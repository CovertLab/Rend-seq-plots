{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Started on June 26, 2018\n",
    "\n",
    "### Rewriting the R-end seq analysis scripts for Lalanne et al 2018.\n",
    "\n",
    "I will start writing up the functions in this notebook, then move it over to python scripts later.\n",
    "\n",
    "Might also make a usable jupyter notebook for future users to have an interactive interface.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TO DO:\n",
    "- Find a way to querey for the genome size without user input\n",
    "- Get rid of any unused packages\n",
    "- Check that all expected files exist before continuting\n",
    "- Rewrite wig loading function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Packages\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#import matlab.engine\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import scipy.io\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User Inputs:\n",
    "\n",
    "This script assumes the genome data is placed in a folder labeled 'genome' and that the data files are within a folder labeled 'data', within this current working directory. The data file name will need to be updated for each analysis set. Put a wildcard '*' in place of the directional portion of the name so that all files can be pulled out at once.\n",
    "\n",
    "If using a genome other than E. coli Version 2 (U00096.2), update the file name below and the genome size in bps. Otherwise it can remain the same. \n",
    "\n",
    "Data file name must contain the directionality of sequencing (either 5r, 3r, 5f, 3f) cannot contain another direction within the name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_subfolder = 'wigs_U000962'\n",
    "data_file_name = \"GSM2971252_Escherichia_coli_WT_Rend_seq_5_exo_MOPS_comp_25s_frag_pooled_*_no_shadow.wig\"\n",
    "genome_annotation_file_name = \"U00096.2.faa\"\n",
    "genome_size = 4639675 # length of genome in base pairs\n",
    "#genome_size = 8589934592"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functions for data loading and parsing\n",
    "def load_wig_data(subfolder, data_file_name, genome_len):\n",
    "    \"\"\"\n",
    "    The purpose of this function is to go create a data file for all the \n",
    "    wig sequencing data. The data is is in the form of a text file (.wig) and contains position \n",
    "    (first column) and count (second column) data.\n",
    "    \n",
    "    This function will simply take in the data files, and put them into an array for use by downstream functions.\n",
    "    \n",
    "    Requires:\n",
    "\n",
    "    -Subfolder where files are located.\n",
    "    -Name of data file containing a wildcard in the place of the directional info for that sequencing run.\n",
    "    \n",
    "    Returns:\n",
    "    \n",
    "    - dense_data_array: a 3 dimensional array.\n",
    "        First dimension: Based on seq file.\n",
    "        Second dimension: counts per position\n",
    "        All positions through the lenght of the genome are recorded.\n",
    "    - file_paths: a list containing all of the file paths \n",
    "    - seq_directions: a list containing the sequencing direction of each file,\n",
    "        in the order it was pulled to create all_data. The directions are either 3' or \n",
    "        5' in either forward or reverse direction.\n",
    "    \"\"\"\n",
    "    #parent_dir = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "    data_directory = os.path.join(os.getcwd(), 'data', subfolder, data_file_name)\n",
    "    file_paths = []\n",
    "    dense_data_array = np.zeros((4, genome_len + 1, 1))\n",
    "    count = 0\n",
    "    for file_path in glob.glob(data_directory):\n",
    "        file_paths.append(file_path)\n",
    "        with open (file_path, 'rt') as f:\n",
    "            for line in f:\n",
    "                if line[0].isdigit():\n",
    "                    x, y = line.split()\n",
    "                    dense_data_array[count, int(x) - 1] = float(y)\n",
    "        count += 1\n",
    "    seq_directions = get_seq_direction(file_paths)\n",
    "    return file_paths, dense_data_array, seq_directions\n",
    "\n",
    "\n",
    "def get_seq_direction(file_names):\n",
    "    \"\"\"\n",
    "    Purpose:\n",
    "    - To extract from the file names the seq direction of the imported wig file. \n",
    "        This is to avoid having to hard-code the directionality in the order the files \n",
    "        are pulled, although the direction options do need to be hard-coded, and \n",
    "        need to be present in the file name.\n",
    "    Requires:\n",
    "    - List of all files that need to be evaluated (this list is output in the function\n",
    "        load_wig_data)\n",
    "    - List of all the possible directions to be evaluated\n",
    "        This list of directions should be the same regardless of the \n",
    "        sample. In this function these directions are hard coded. See possible_directions.\n",
    "    Returns:\n",
    "    -Read direction as a list of strings based on the order the files were imported \n",
    "        and are consequently stored.\n",
    "    - The positions are listed in the order that the files were pulled and extracted\n",
    "    in the function load_wig_data(). So the positions in this list reflect the \n",
    "    order of that data.\n",
    "    \"\"\"\n",
    "    possible_directions = ['5f', '5r', '3f', '3r']\n",
    "    directions = []\n",
    "    for name in file_names:\n",
    "        for direction in possible_directions:\n",
    "            if direction in name.lower():\n",
    "                directions.append(direction)\n",
    "    return directions\n",
    "\n",
    "def simplify_genome_annotation(annotation_file_name):\n",
    "    \"\"\"\n",
    "    The purpose of this function is to pull out genome annotation information from the \n",
    "    original .faa file.\n",
    "\n",
    "    Requires:\n",
    "        -.faa genome annotation file in /genome/ subdirectory.\n",
    "\n",
    "    Returns:\n",
    "        -List where for each gene the the locus tag, gene name, gene name,\n",
    "            gene direction, start position, and end position are recorded\n",
    "            For example:\n",
    "            ['b0001', 'thrL', '+', 190.0, 255.0]\n",
    "\n",
    "    Note:\n",
    "        -The annotation file has to be annotated in a very specific format.\n",
    "        For example:\n",
    "        >[locus_tag=b0585] [gene=fes] [protein=enterobactin/ferric enterobactin esterase] [location=612038..613162]\n",
    "        -If file is not in correct format, update code below, or restructure file.\n",
    "    \"\"\"\n",
    "    #parent_dir = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "    file_path = os.path.join(os.getcwd(), 'genome', genome_annotation_file_name)\n",
    "    line_marker = '>'\n",
    "    annotation_list = []\n",
    "    with open (file_path, 'rt') as in_file:  \n",
    "        for line in in_file:\n",
    "            if line_marker in line:\n",
    "                annotation_list.append(parse_single_gene(line))\n",
    "    return annotation_list\n",
    "\n",
    "def parse_single_gene(single_line):\n",
    "    \"\"\"\n",
    "    Single text line (corresponding to a single gene) originally extracted from gene \n",
    "    anotation file in the function simplify_genome_annotation(), and parses it to \n",
    "    give extract the anotation information.\n",
    "    Requires:\n",
    "        - Single gene text line extracted from the genome annotation file.\n",
    "    \n",
    "    Returns:\n",
    "        -A list contining the locus tag, gene name, gene direction ('+' or '-')(as strings), \n",
    "            and gene start and stop for each gene.\n",
    "    Note:\n",
    "        - For get_gene_direction_info the data supplied are taken from\n",
    "            gene_info_not_parsed[-1], since sometimes protein descriptions\n",
    "            contain [] and will throw off indexing if choosing the third \n",
    "            position. But the location information is always stored last.\n",
    "    \"\"\"\n",
    "    gene_info_not_parsed = splice_string_to_attributes(single_line)\n",
    "    locus_tag = get_locus_tag(gene_info_not_parsed[0])\n",
    "    gene_name = get_gene_name(gene_info_not_parsed[1])\n",
    "    gene_direction, gene_start, gene_stop = get_gene_direction_info(gene_info_not_parsed[-1])\n",
    "    return [locus_tag, gene_name, gene_direction, gene_start, gene_stop]  \n",
    "\n",
    "def splice_string_to_attributes(single_line):\n",
    "    \"\"\"\n",
    "    Requires:\n",
    "        -A line of text from the genome annotation file, \n",
    "    Returns:\n",
    "        - list containing the parts necessary for further down stream string\n",
    "        splicing. \n",
    "        -At this point it simply separates information based on whether it is surrounded by square\n",
    "        brackets.\n",
    "    \"\"\"\n",
    "    split_string = re.split(r'[\\[\\]]', single_line)\n",
    "    strip_list = [gene_data for gene_data in split_string if gene_data.strip()][1:]\n",
    "    return strip_list\n",
    "\n",
    "def get_locus_tag(locus_info):\n",
    "    \"\"\"\n",
    "    Requires:\n",
    "        -String in the form: locus_tag=b0586,\n",
    "    Returns:\n",
    "        -Locus tag (string)\n",
    "    \"\"\"\n",
    "    locus = locus_info.split('=')[1]\n",
    "    return locus\n",
    "\n",
    "def get_gene_name(gene_info):\n",
    "    \"\"\"\n",
    "    Requires:\n",
    "        -String in the form: gene=ybdZ,\n",
    "    Returns:\n",
    "        -Gene name (string)\n",
    "    Note:\n",
    "    Requires that no more than a single gene name is assigned per gene. \n",
    "    \"\"\"\n",
    "    name = gene_info.split('=')[1]\n",
    "    return name\n",
    "\n",
    "def get_gene_direction_info(direction_info):\n",
    "    \"\"\"\n",
    "    Requires:\n",
    "        - Takes in a string in the form: location=417113..418408 or\n",
    "        location=complement(414974..416176).\n",
    "    Returns:\n",
    "        -If is the complemnent returns the direction as '-', or \n",
    "        else returns '+'.\n",
    "        -Returns the start and stop positions as floats.\n",
    "    \"\"\"\n",
    "    start = [] \n",
    "    stop = []\n",
    "    location_str = direction_info.split('=')[1]\n",
    "    direction  = ['-' if '(' in location_str else '+'][0]\n",
    "    \n",
    "    if direction == \"+\":\n",
    "        start, stop = location_str.split('..')\n",
    "    else:\n",
    "        indices = [location_str.find(i) for i in ['(', ')']]\n",
    "        start, stop = location_str[indices[0]+1:indices[1]].split('..')\n",
    "    return direction , float(start), float(stop)\n",
    "\n",
    "#Functions for computations\n",
    "\n",
    "def create_fft_filter(direction, genome_len, half_width):\n",
    "    filt = np.zeros((genome_len + 1, 1))\n",
    "\n",
    "    if 'f' in direction:\n",
    "        filt[genome_len / 2 + 1 : genome_len / 2 + 2 * half_width_z_score] = 1. / (2. * half_width_z_score)\n",
    "    elif 'r' in direction:\n",
    "        filt[genome_len / 2 - 2 * half_width_z_score : genome_len / 2 - 1] = 1. / (2. * half_width_z_score)\n",
    "    else:\n",
    "        'Fourier tranform filter could not be computed bc the direction of the seq file has not been recorded properly'\n",
    "    return filt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_file_names, all_data, seq_directions = load_wig_data(data_subfolder, data_file_name, genome_size)\n",
    "genome_annotation = simplify_genome_annotation(genome_annotation_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 4639676, 1)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Peak and Z scores for wig file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters for peak z score and step z score calculation\n",
    "\n",
    "\n",
    "half_width_z_score = 100   # half width of window for averaging for peak z score\n",
    "half_width_step = 100.      # half width of window for averaging for step z score\n",
    "average_threshold = 0.25   # average read density (read/nt) threshold for consideration\n",
    "gap_z = 2.                  # gap left out (both sides) of central position for peak z score \n",
    "gap_step = 3.              # gap left out (both sides) of central position for step z score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_data_set = np.squeeze(all_data[3])\n",
    "len_data = len(single_data_set)\n",
    "direction = seq_directions[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_for_fft = create_fft_filter(direction, genome_size, half_width_z_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['5f', '3f', '5r', '3r']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_directions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters_for_fft = []\n",
    "for direction in seq_directions:\n",
    "    filters_for_fft.append(create_fft_filter(direction, genome_size, half_width_z_score))\n",
    "filters_for_fft = np.asarray(filters_for_fft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.],\n",
       "        [ 0.],\n",
       "        [ 0.],\n",
       "        ..., \n",
       "        [ 0.],\n",
       "        [ 0.],\n",
       "        [ 0.]],\n",
       "\n",
       "       [[ 0.],\n",
       "        [ 0.],\n",
       "        [ 0.],\n",
       "        ..., \n",
       "        [ 0.],\n",
       "        [ 0.],\n",
       "        [ 0.]],\n",
       "\n",
       "       [[ 0.],\n",
       "        [ 0.],\n",
       "        [ 0.],\n",
       "        ..., \n",
       "        [ 0.],\n",
       "        [ 0.],\n",
       "        [ 0.]],\n",
       "\n",
       "       [[ 0.],\n",
       "        [ 0.],\n",
       "        [ 0.],\n",
       "        ..., \n",
       "        [ 0.],\n",
       "        [ 0.],\n",
       "        [ 0.]]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filters_for_fft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.io.savemat('filters_for_fft.mat', {'filters_for_fft':filters_for_fft})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.io.savemat('all_data.mat', {'all_data':all_data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fft_data = np.fft.fft(single_data_set, len_data)\n",
    "#ft_filter = np.fft.fft(filter_for_fft, len_data)\n",
    "\n",
    "\n",
    "#fft_data_squared = np.fft.fft(np.square(single_data_set), len_data) # This step takes ~20 seconds\n",
    "\n",
    "#average_data = np.fft.fftshift(np.fft.ifft((ft_filter.T * fft_data), len_data))\n",
    "\n",
    "#std_data = np.sqrt(np.fft.fftshift(np.fft.ifft(ft_filter.T * fft_data_squared, len_data)) - np.square(average_data))\n",
    "\n",
    "#z_peak = (average_data > average_threshold) * (single_data_set - average_data) / (std_data + (average_data == 0))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
